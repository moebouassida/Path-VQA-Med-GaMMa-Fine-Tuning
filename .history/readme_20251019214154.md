# ğŸ§¬ Path-VQA Med-GaMMa Fine-Tuning

** Fine-tune Med-GaMMa on an enhanced version of the Path-VQA dataset, where answers are more pathologically detailed. Deploy via FastAPI with GPU Docker support and MLflow tracking.**

ğŸš§ ** Live demo is currently in progress! **

## âœ… Features
ğŸ“· Upload pathology images (via URL) and ask clinical questions

ğŸ©º Predict pathologically accurate answers using Med-GaMMa fine-tuned on enhanced Path-VQA

âš¡ GPU acceleration supported (CUDA + Docker)

ğŸ“Š MLflow integration for tracking training metrics, hyperparameters, and model checkpoints

ğŸ“ Interactive API documentation via Swagger UI (/docs)

ğŸ§± Modular, clean project structure for easy extension

## ğŸ“ Project Structure

| File / Folder | Description |

| app/main.py | FastAPI app + inference logic |

| scripts/train.py | Fine-tuning script using LoRA + SFTTrainer |

| scripts/data_preprocessing.py | Converts Path-VQA dataset to conversation format |

| configs/config.yaml | Hyperparameters and training configuration |

| outputs/ | Fine-tuned Med-GaMMa model adapters and checkpoints |

| mlruns/ | MLflow experiment tracking folder |

| Dockerfile | GPU-enabled Docker image |

| requirements.txt | Python dependencies |

| README.md | Project documentation |

## ğŸš€ Setup & Run

Clone the repository

No local dataset needed â€” Path-VQA is downloaded directly from Hugging Face.

Run Locally (without Docker)

pip install -r requirements.txt
python scripts/train.py
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

Run with Docker (GPU Recommended)

Requires NVIDIA GPU and NVIDIA Container Toolkit:

docker build -t pathvqa-medgemma-gpu .
docker run --gpus all -p 8000:8000 pathvqa-medgemma-gpu

## ğŸ“¤ API Endpoints

| Method | Endpoint | Description |
| POST | /predict | Upload image URL + question â†’ returns pathologically detailed answer |
| GET | /health | Health check | 
| GET | /docs | Interactive Swagger UI |

Example request:

curl -X POST "http://localhost:8000/predict" \
-H "Content-Type: application/json" \
-d '{
    "image_url": "https://example.com/pathology_image.jpg",
    "question": "What type of tissue is shown?"
}'

Response:

{
  "answer": "This is glandular epithelium tissue with high stromal content..."
}

## ğŸ“Š MLflow Integration

Metrics, hyperparameters, and trained models are logged to ./mlruns.

Start MLflow UI:

mlflow ui --backend-store-uri ./mlruns
# Open in browser: http://localhost:5000

Tracked items:

âœ… Training loss & validation metricsâœ… Hyperparameters (LR, batch size, epochs)âœ… Saved LoRA adapters / model checkpoints

## âš™ Technologies Used

| Component | Technology |

| Backend | API FastAPI |

| Vision-Language Model | Med-GaMMa |

| Fine-Tuning | LoRA + SFTTrainer (TRL) |

| Experiment | Tracking MLflow |

| Containerization | Docker + NVIDIA Runtime |

| Dataset | Enhanced Path-VQA (answers pathologically detailed) |

| Input | Image + Question (JSON) |

| Output | Text answer (JSON) |


## ğŸ–¼ Project Overview Diagram

Path-VQA Enhanced Dataset
        â”‚
        â–¼
Data Preprocessing
        â”‚
        â–¼
LoRA Fine-Tuning (Med-GaMMa)
        â”‚
        â–¼
Saved Adapters / Checkpoints
        â”‚
        â–¼
FastAPI Inference API
        â”‚
        â–¼
User Input: Image + Question
        â”‚
        â–¼
Model Output: Pathologically Detailed Answer

## ğŸ”„ Roadmap

âœ… GPU-enabled Docker image
âœ… MLflow integration
ğŸ“Š Web dashboard for predictions & visualizations (in progress)
â˜  Cloud deployment (AWS)

